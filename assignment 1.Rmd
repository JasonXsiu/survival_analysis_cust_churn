```{r}
library(tidyverse)
library(readr)
library(survminer)
library(survival)
library(broom)
library(ggfortify)
library(tidyr)
## Remove the line break in the file name! churn_dat <-
churn_dat <-read_csv("https://raw.githubusercontent.com/square/pysurvival/master/pysurvival/datasets/churn.csv")
churn_dat <- churn_dat %>% filter(months_active > 0)
set.seed(12345)
```

====================== Q1 A


```{r Q1-function}
#t = at a particular time period
#n = # of the individuals that are still surviving at t (i.e customer still using our services)
#d = # of event at t (i.e customer left)

KM_estimate <- function (time, event) 
{
    sorted_time <- sort(time)
    event <- event[order(time)] # event being ordered
    ni <- length(time):1
    ni <- ni[!duplicated(sorted_time)]
    di <- tapply(event, sorted_time, sum)
    ti <- unique(sorted_time)
    si <- (ni - di)/ni
    cum_survivial_i <- cumprod(si)
    cum_risk_i <- 1 - cum_survivial_i
    results <- cbind(time = ti, n_risk = ni, n_events = di, condsurv = si, 
        survival = cum_survivial_i, risk = cum_risk_i)
    dimnames(results)[1] <- list(NULL)
    results[, ]
}

```


```{r Q1-Plot-full_data}
time <-  churn_dat$months_active 
event <- churn_dat$churned
result <- KM_estimate(time, event)
result <- as.data.frame(result)
```



```{r}
ggplot(result, aes(x=time, y = survival))+
  geom_point()+
  geom_step ()+
  theme_bw()+
  ggtitle("The Kaplan-Meier curve for the full data") + 
  labs(x= 'Time',
         y="Prob.Survival")
```



====================== Q1 B


```{r}
df_10to50 <-  churn_dat %>% filter(company_size == "10-50")

s1_time <-  df_10to50$months_active 
s1_event <- df_10to50$churned
s1_result <- KM_estimate(s1_time, s1_event)
s1_result <- as.data.frame(s1_result)


#100-250
df_100to250 <- churn_dat %>% filter(company_size ==  "100-250")

s2_time <-  df_100to250$months_active 
s2_event <- df_100to250$churned
s2_result <- KM_estimate(s2_time, s2_event)
s2_result <- as.data.frame(s2_result)



#"50-100" 
df_50to100 <- churn_dat %>% filter(company_size ==  "50-100")

s3_time <-  df_50to100$months_active 
s3_event <- df_50to100$churned
s3_result <- KM_estimate(s3_time, s3_event)
s3_result <- as.data.frame(s3_result)



#"1-10"
df_1to10 <- churn_dat %>% filter(company_size ==  "1-10")

s4_time <-  df_1to10$months_active 
s4_event <- df_1to10$churned
s4_result <- KM_estimate(s4_time, s4_event)
s4_result <- as.data.frame(s4_result)


# "self-employed"

df_self_employed <- churn_dat %>% filter(company_size ==  "self-employed")
s5_time <-  df_self_employed$months_active 
s5_event <- df_self_employed$churned
s5_result <- KM_estimate(s5_time, s5_event)
s5_result <- as.data.frame(s5_result)

```

```{r plot-by-sizes}

colors <- c("10-50"="red", "100-250" = "blue","50-100" = "green","1-10" = "pink","self-employed" = "black")

ggplot()+
    geom_step(data =s1_result,  
              aes(x=time, y = survival,
              color = "10-50"),
              size = 1.5)+
    geom_step(data =s2_result,  
              aes(x=time, y = survival,
              color = "100-250"),
              size = 1.5)+
    geom_step(data =s3_result,  
              aes(x=time, y = survival,
              color = "50-100"),
              size = 1.5)+
    geom_step(data =s4_result,  
              aes(x=time, y = survival,
              color = "1-10"),
              size = 1.5)+
    geom_step(data =s5_result,  
              aes(x=time, y = survival,
              color = "self-employed"),
              size = 1.5,
              linetype = 2)+
    labs(x= 'Time',
         y="Prob.Survival",
         color = 'Legend')+
        scale_color_manual(values = colors)+
    theme_bw()+
    theme(legend.position = c(.1,.26))+
    ggtitle("The Kaplan-Meier curve for each company size")





```


Interpretation :

The Kaplan-Meier curves for each respective company size are overall pretty similar in shape. They all exhibit the same early drop offs in survival probability followed by more stability in the back two thirds of the time period.

The somewhat outlier of the group however is the company size of 100 to 250 clients. Its curve drops lower, a lot earlier than the rest of the curves, this indicates it is losing customers quicker than the others and, with the curve finishing lowest out of the five, also illustrates that it has a lower rate of keeping customers long term and hence a higher customer churn rate. Another interesting feature of the graph is the self-employed data. The graph for the self-employed companies shows the graph running off from about time 6 indicating that no more clients had churned from that point onwards to the point of censoring. However, this company size also had the lowest number of observations being only 62 which could explain the disparity in customer churn to the other companies. 

Although size of data definitely plays a role in determining the shape and pattern of the graphs, a more logical reason to explain the graphs could be that companies with larger numbers of clients may struggle to attain the same depth and quality of business-client relations as their low client number counterparts, hence resulting in higher customer churn rates.


====================== Q2 A

```{r function-to-find-median}


near_median <- function(fit){
  if (length(fit$n) > 1) {
    stop("This only works for a single survival curve!")
  }
  index <- which.min(abs(fit$surv - 0.5))
  return(fit$time[index])
}

average_median <- function(fit) {
if (length(fit$n) > 1) {
stop("This only works for a single survival curve!")
}
suppressWarnings(lower_ind <- which.min(log(fit$surv - 0.5)))
suppressWarnings(upper_ind <- which.min(log(0.5 - fit$surv)))
return((fit$time[lower_ind] + fit$time[upper_ind])/2)
}


```


```{r filter_df}

filter_df <- function(size){
df <- churn_dat %>% filter(company_size == size)
time <-  df$months_active 
event <- df$churned
fit <- surv_fit(Surv(time,event)~1, data = df) 

return(fit)
}

```

```{r 10-50}
#here estimate median based on sizes
fit <- filter_df("10-50")
fit %>% tidy()
s1_median <- average_median(fit)
```
'The median time is where the survival probability is equal to 0.5. Although there is no exact time where this occurs we know that the median exists between times 5 and 6. As the survival probabilities of the two times are near equally far from 0.5 (which are  0.505 and  0.493 respectively).

Therefore, for size 10-50, the average median is `r average_median(fit)`

```{r 100-250}
#here estimate median based on sizes
fit <- filter_df("100-250")
fit %>% tidy()
s2_median <- near_median(fit)

```
The median time is where the survival probability is equal to 0.5. Although there is no exact time where this occurs we know that the median exists between times 5 and 6. As the survival probabilities of the two times are NOT  nearly equal to 0.5 (which are  0.54 and  0.45 respectively), we can use the average median of 5.5 as the most suitable measure of the median.

Therefore, for size 100-250, the near median is `r near_median(fit)`


```{r 50-100}
#here estimate median based on sizes
fit <- filter_df("50-100")
fit %>% tidy()
s3_median <- average_median(fit)

```
The median time is where the survival probability is equal to 0.5. Although there is no exact time where this occurs we know that the median exists between times 5 and 6. As the survival probabilities of the two times are  nearly equal to  0.5 (which are  0.51 and  0.48 respectively)

Therefore, for size 50-100, the near median is `r average_median(fit)`



```{r 1-10}
#here estimate median based on sizes
fit <- filter_df("1-10")
fit %>% tidy()
s4_median <- average_median(fit)

```
The median time is where the survival probability is equal to 0.5. Although there is no exact time where this occurs we know that the median exists between times 5 and 6. As the survival probabilities of the two times are  nearly equal to  0.5 (which are  .50 and  .49 respectively)

Therefore, for size 1-10, the near median is `r average_median(fit)`

```{r self-employed}
#here estimate median based on sizes
fit <- filter_df("self-employed")
fit %>% tidy()
s5_median <- average_median(fit)

```
The median time is where the survival probability is equal to 0.5. Although there is no exact time where this occurs we know that the median exists between times 5 and 6. As the survival probabilities of the two times are  nearly equal to  0.5 (which are  .50 and  .47 respectively)

Therefore, for size "self-employed", the near median is `r average_median(fit)`



====================== Q2 B
Since the previously defined function could only work for a single survival curve, therefore, this function is made. 

The following function was reference from surv_median from the survminer package. Nonetheless, its the median survival with upper and lower confidence limits for the median at 95% confidence levels. So, I changed it to a way that it can compute the median at 90% CI instead. 



```{r median_at_90_percent}
median_at_90_percent <- function (fit, combine = FALSE) 
{
    .median <- function(fit) {
        if (!is.null(fit$strata) | is.matrix(fit$surv)) {
            .table <- as.data.frame(summary(fit)$table)
        }
        else {
            .table <- t(as.data.frame(summary(fit)$table)) %>% 
                as.data.frame()
            rownames(.table) <- "All"
        }
        .table$strata <- rownames(.table)
        .table <- .table %>% dplyr::select_(.dots = c("strata", 
            "median", "`0.9LCL`", "`0.9UCL`"))
        colnames(.table) <- c("strata", "median", 
            "lower", "upper")
        rownames(.table) <- NULL
        .table
    }
   .median(fit)
}
```


```{r plotting-hist}
#create a function for plotting

plot_boot_data <- function(experiments, size, s_median){
  fit <- survfit(Surv(time_star, event_star) ~ experiment, data = experiments,conf.int= 0.9)
  #get the median of surv
  surv_med <- median_at_90_percent(fit)
  surv_med <- data.frame(surv_med)
  med <-  surv_med$median
  med <- data.frame(med)
  #get the upper CI
  upper <-  mean(surv_med$upper, na=T)

  #get the lower CI
  lower <- mean(surv_med$lower, na=T) 

  ggplot(med , aes(x = med, fill= med)) +
    geom_histogram(binwidth = .8)+
    geom_vline(xintercept = upper, colour="blue",linetype="dashed")+
    geom_vline(xintercept = lower, colour="blue",linetype="dashed")+
    geom_vline(xintercept = s_median, colour="black")+
    ggtitle(  paste("The estimate of the median for", size))+
      labs(x= 'Median',
         y="Count")+
    theme_bw()
    
}
```

```{r bootstrap}
#create a function of  the dataframe by sizes
boot <- function(size,n_sims){
#1. filter data into a particular size
df <- churn_dat %>% filter(company_size == size)
n <-  nrow(df)
#2. run the bootstrap
experiments <-  tibble(experiment = rep(1:n_sims, each = n),
                     index = sample(1:n, size = n * n_sims, replace = TRUE),
                     time_star = df$months_active[index],
                     event_star = df$churned[index])
return(experiments)
}

```



```{r}
set.seed(999)
#"10-50"
df_10to50 <- boot("10-50",1000)

plot_boot_data(df_10to50, "10-50",s1_median)

#"100-250"
df_100to250 <- boot("100-250",1000)
plot_boot_data(df_100to250,"100-250",s2_median)

#"50-100"
df_50to100 <- boot("50-100",1000)
plot_boot_data(df_50to100,"50-100",s3_median)

#"1-10"              
df_1to10 <- boot("1-10",1000)
plot_boot_data(df_1to10,"1-10",s4_median)


#"self-employed"
df_self_employed <- boot("self-employed",1000)
plot_boot_data(df_self_employed,"self-employed",s5_median)
```




